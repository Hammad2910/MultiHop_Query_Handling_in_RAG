{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17428c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\hammad workings\\Thesis\\Multihop for Urdu\\Multihop for Urdu\\code\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\hammad workings\\Thesis\\Multihop for Urdu\\Multihop for Urdu\\code\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\23030013\\.cache\\huggingface\\hub\\models--bigscience--bloomz-560m. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate to English: Je t’aime. I love you.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"bigscience/bloomz-560m\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=\"auto\", device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504675b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\hammad workings\\\\Thesis\\\\Multihop for Urdu\\\\Multihop for Urdu\\\\model_weights\\\\bloomz-560m\\\\tokenizer_config.json',\n",
       " 'C:\\\\hammad workings\\\\Thesis\\\\Multihop for Urdu\\\\Multihop for Urdu\\\\model_weights\\\\bloomz-560m\\\\special_tokens_map.json',\n",
       " 'C:\\\\hammad workings\\\\Thesis\\\\Multihop for Urdu\\\\Multihop for Urdu\\\\model_weights\\\\bloomz-560m\\\\tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save_directory = \"C:\\\\hammad workings\\\\Thesis\\\\Multihop for Urdu\\\\Multihop for Urdu\\\\model_weights\\\\bloomz-560m\"\n",
    "# model.save_pretrained(save_directory)\n",
    "# tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80276ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_directory = \"C:\\\\hammad workings\\\\Thesis\\\\Multihop for Urdu\\\\Multihop for Urdu\\\\model_weights\\\\bloomz-560m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(load_directory)\n",
    "model = AutoModelForCausalLM.from_pretrained(load_directory, torch_dtype=\"auto\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9237efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_urdu_question(urdu_question):\n",
    "    # Create the prompt with English instructions and Urdu question\n",
    "    prompt = f\"\"\"Classify the following Urdu question as either \"simple\" (requires no context), \"singlehop\" (requires one inference step), or \"multihop\" (requires multiple reasoning steps):\n",
    "\n",
    "{urdu_question}\n",
    "\n",
    "Classification:\"\"\"\n",
    "    \n",
    "    # Tokenize and generate\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        inputs, \n",
    "        max_new_tokens=10,  # We only need a short answer\n",
    "        temperature=0.1,    # Lower temperature for more deterministic output\n",
    "        do_sample=False,    # Use greedy decoding for consistent results\n",
    "        num_beams=3         # Simple beam search for better quality\n",
    "    )\n",
    "    \n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract just the classification from the result\n",
    "    # This will return everything after the prompt\n",
    "    classification = result.replace(prompt, \"\").strip()\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0ab2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_urdu_question(urdu_question):\n",
    "    prompt = f\"\"\"\n",
    "You are a reasoning expert. Your task is to classify the complexity of a question written in Urdu into one of three categories:\n",
    "\n",
    "- \"simple\": A fact-based question that can be answered without needing additional context or inference.\n",
    "- \"singlehop\": A question that requires one reasoning step or fact connection.\n",
    "- \"multihop\": A question that needs multiple reasoning steps or combining information from different parts.\n",
    "\n",
    "Here are a few examples:\n",
    "\n",
    "Example 1:\n",
    "Question (Urdu): پاکستان کا دارالحکومت کیا ہے؟\n",
    "Classification: simple\n",
    "\n",
    "Example 2:\n",
    "Question (Urdu): وہ شخص کون تھا جو قائد اعظم کے بعد گورنر جنرل بنا؟\n",
    "Classification: singlehop\n",
    "\n",
    "Example 3:\n",
    "Question (Urdu): وہ سائنسدان کون ہے جس نے نظریہ ارتقاء پیش کیا، اور اس کا اثر بیسویں صدی کی حیاتیات پر کیا پڑا؟\n",
    "Classification: multihop\n",
    "\n",
    "Now classify the following question:\n",
    "\n",
    "Question (Urdu): {urdu_question}\n",
    "Classification:\"\"\"\n",
    "\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_new_tokens=10,\n",
    "        temperature=0.1,\n",
    "        do_sample=False,\n",
    "        num_beams=3\n",
    "    )\n",
    "\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    classification = result.replace(prompt, \"\").strip()\n",
    "\n",
    "    return classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "187b392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\hammad workings\\Thesis\\Multihop for Urdu\\Multihop for Urdu\\code\\venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: پاکستان کا دارالحکومت کیا ہے؟\n",
      "Classification: simple\n",
      "Question: جس ملک کی سرحد چین کے ساتھ ملتی ہے اس کا دارالحکومت کیا ہے؟\n",
      "Classification: singlehop\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "urdu_question = \"پاکستان کا دارالحکومت کیا ہے؟\"  # \"What is the capital of Pakistan?\"\n",
    "classification = classify_urdu_question(urdu_question)\n",
    "print(f\"Question: {urdu_question}\")\n",
    "print(f\"Classification: {classification}\")\n",
    "\n",
    "# You can test with different complexity questions\n",
    "urdu_question2 = \"جس ملک کی سرحد چین کے ساتھ ملتی ہے اس کا دارالحکومت کیا ہے؟\"  # Multihop: \"What is the capital of the country that borders China?\"\n",
    "classification2 = classify_urdu_question(urdu_question2)\n",
    "print(f\"Question: {urdu_question2}\")\n",
    "print(f\"Classification: {classification2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70df3653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\hammad workings\\Thesis\\Multihop for Urdu\\Multihop for Urdu\\code\\venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 98/98 [13:57<00:00,  8.55s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(\"C:\\\\hammad workings\\\\Thesis\\\\Multihop for Urdu\\\\Multihop for Urdu\\\\Dataset\\\\Hotpotqa\\\\1000_paras_100_queries\\\\translated_dataset_100_qna.csv\")  # Replace with your actual file name\n",
    "\n",
    "# Ensure 'translated_question' column exists\n",
    "if 'translated_question' not in df.columns:\n",
    "    raise ValueError(\"Column 'translated_question' not found in the CSV.\")\n",
    "\n",
    "# Add a new column for the classification results\n",
    "tqdm.pandas()  # Enables progress bar with apply\n",
    "df['question_type'] = df['translated_question'].progress_apply(classify_urdu_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "540daffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [04:09<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Total questions: 98\n",
      "✅ Correctly classified: 39\n",
      "✅ Accuracy: 39.80%\n",
      "\n",
      "🔍 Accuracy by level:\n",
      "  easy: 44.44% (8/18)\n",
      "  medium: 46.67% (14/30)\n",
      "  hard: 34.00% (17/50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def classify_urdu_question(urdu_question):\n",
    "    prompt = f\"\"\"\n",
    "You are a reasoning expert. Your task is to classify the complexity of a question written in Urdu into one of three categories:\n",
    "\n",
    "- \"simple\": A fact-based question that can be answered without needing additional context or inference.\n",
    "- \"singlehop\": A question that requires one reasoning step or fact connection.\n",
    "- \"multihop\": A question that needs multiple reasoning steps or combining information from different parts.\n",
    "\n",
    "Here are a few examples:\n",
    "\n",
    "Example 1:\n",
    "Question (Urdu): پاکستان کا دارالحکومت کیا ہے؟\n",
    "Classification: simple\n",
    "\n",
    "Example 2:\n",
    "Question (Urdu): وہ شخص کون تھا جو قائد اعظم کے بعد گورنر جنرل بنا؟\n",
    "Classification: singlehop\n",
    "\n",
    "Example 3:\n",
    "Question (Urdu): وہ سائنسدان کون ہے جس نے نظریہ ارتقاء پیش کیا، اور اس کا اثر بیسویں صدی کی حیاتیات پر کیا پڑا؟\n",
    "Classification: multihop\n",
    "\n",
    "Now classify the following question:\n",
    "\n",
    "Question (Urdu): {urdu_question}\n",
    "Classification:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3:8b',\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        reply = response['message']['content'].strip().lower()\n",
    "\n",
    "        # Normalize to allowed values\n",
    "        for label in ['simple', 'singlehop', 'multihop']:\n",
    "            if label in reply:\n",
    "                return label\n",
    "\n",
    "        print(f\"⚠️ Unexpected response: {reply}\")\n",
    "        return \"unknown\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing question: {urdu_question}\\n↪ {e}\")\n",
    "        return \"error\"\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"C:\\\\hammad workings\\\\Thesis\\\\Multihop for Urdu\\\\Multihop for Urdu\\\\Dataset\\\\Hotpotqa\\\\1000_paras_100_queries\\\\translated_dataset_100_qna.csv\")\n",
    "\n",
    "# Make sure necessary columns exist\n",
    "required_columns = {'translated_question', 'level'}\n",
    "if not required_columns.issubset(df.columns):\n",
    "    raise ValueError(f\"Missing one of the required columns: {required_columns - set(df.columns)}\")\n",
    "\n",
    "# Enable tqdm for apply\n",
    "tqdm.pandas()\n",
    "\n",
    "# Generate temporary 'question_type' in memory (NOT saving to CSV)\n",
    "df_temp = df.copy()\n",
    "df_temp['question_type'] = df_temp['translated_question'].progress_apply(classify_urdu_question)\n",
    "\n",
    "# Define classification check logic\n",
    "def is_correct(row):\n",
    "    level = str(row['level']).strip().lower()\n",
    "    q_type = str(row['question_type']).strip().lower()\n",
    "\n",
    "    if level == 'easy' and q_type in {'simple', 'singlehop'}:\n",
    "        return True\n",
    "    elif level in {'medium', 'hard'} and q_type == 'multihop':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Apply correctness check\n",
    "df_temp['correct_classification'] = df_temp.apply(is_correct, axis=1)\n",
    "\n",
    "# Summary stats\n",
    "total = len(df_temp)\n",
    "correct = df_temp['correct_classification'].sum()\n",
    "accuracy = correct / total * 100\n",
    "\n",
    "print(f\"\\n✅ Total questions: {total}\")\n",
    "print(f\"✅ Correctly classified: {correct}\")\n",
    "print(f\"✅ Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Per-level analysis\n",
    "print(\"\\n🔍 Accuracy by level:\")\n",
    "for level in df_temp['level'].unique():\n",
    "    subset = df_temp[df_temp['level'].str.lower() == level.lower()]\n",
    "    correct_subset = subset['correct_classification'].sum()\n",
    "    total_subset = len(subset)\n",
    "    acc = correct_subset / total_subset * 100 if total_subset else 0\n",
    "    print(f\"  {level}: {acc:.2f}% ({correct_subset}/{total_subset})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b394367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "ollama.pull(\"llama3:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c7aa576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [04:35<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Total questions: 98\n",
      "✅ Correctly classified: 64\n",
      "✅ Accuracy: 65.31%\n",
      "\n",
      "🔍 Accuracy by level:\n",
      "  easy: 16.67% (3/18)\n",
      "  medium: 73.33% (22/30)\n",
      "  hard: 78.00% (39/50)\n",
      "\n",
      "❌ Misclassified questions:\n",
      "                                  translated_question level question_type\n",
      "0   سیری بی 2017 - 2017 (اسپانسرشپ کی وجوہات کی بن...  easy      multihop\n",
      "1   \"آکسفورڈ کالج کے ایک ساتھی ایلک نیلر ڈکن نے کہ...  easy      multihop\n",
      "2   \"جراسک پارک کے اداکار ڈیوڈ ہنری ہوانگ نے \"\"دی ...  easy      multihop\n",
      "3   کون سا کردار ، ڈین کاسٹیلینیٹا کی آواز ، سمپسن...  easy      multihop\n",
      "5   امریکی باسکٹ بال ٹیم نے اس سال کے آخر میں شکاگ...  easy      multihop\n",
      "6   لیٹروب بریوری کمپنی ، جو 1839 میں قائم ہوئی تھ...  easy      multihop\n",
      "7   امریکی فوج کے ایک افسر اور منشیات کے اسمگلنگ ک...  easy      multihop\n",
      "8   اینڈریو مارٹن ڈوبر ، ایک امریکی مخلوط مارشل آر...  easy      multihop\n",
      "9   ایمینم کے البم مارشل میتھرز ایل پی 2 پر کون سا...  easy      multihop\n",
      "11  ڈیان ولکنز اور اسٹیون اسپیلبرگ نیو ہالی ووڈ کے...  easy      multihop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Classification Function ---\n",
    "def classify_urdu_question(urdu_question):\n",
    "    prompt = f\"\"\"\n",
    "You are a reasoning expert. Your task is to classify the complexity of a question written in Urdu into one of two categories:\n",
    "\n",
    "- \"singlehop\": A question that can be answered with one reasoning step or simple fact retrieval.\n",
    "- \"multihop\": A question that requires multiple reasoning steps or combining information from different parts.\n",
    "\n",
    "Here are a few examples:\n",
    "\n",
    "Example 1:\n",
    "Question (Urdu): پاکستان کا دارالحکومت کیا ہے؟\n",
    "Classification: singlehop\n",
    "\n",
    "Example 2:\n",
    "Question (Urdu): وہ شخص کون تھا جو قائد اعظم کے بعد گورنر جنرل بنا؟\n",
    "Classification: singlehop\n",
    "\n",
    "Example 3:\n",
    "Question (Urdu): وہ سائنسدان کون ہے جس نے نظریہ ارتقاء پیش کیا، اور اس کا اثر بیسویں صدی کی حیاتیات پر کیا پڑا؟\n",
    "Classification: multihop\n",
    "\n",
    "Now classify the following question:\n",
    "\n",
    "Question (Urdu): {urdu_question}\n",
    "Classification:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3:8b',\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        reply = response['message']['content'].strip().lower()\n",
    "\n",
    "        # Normalize output\n",
    "        if 'multihop' in reply:\n",
    "            return 'multihop'\n",
    "        elif 'singlehop' in reply or 'simple' in reply:\n",
    "            return 'singlehop'\n",
    "\n",
    "        print(f\"⚠️ Unexpected response: {reply}\")\n",
    "        return \"unknown\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing question: {urdu_question}\\n↪ {e}\")\n",
    "        return \"error\"\n",
    "\n",
    "# --- Load Dataset ---\n",
    "df = pd.read_csv(\"C:\\\\hammad workings\\\\Thesis\\\\Multihop for Urdu\\\\Multihop for Urdu\\\\Dataset\\\\Hotpotqa\\\\1000_paras_100_queries\\\\translated_dataset_100_qna.csv\")\n",
    "\n",
    "# Ensure required columns exist\n",
    "required_columns = {'translated_question', 'level'}\n",
    "if not required_columns.issubset(df.columns):\n",
    "    raise ValueError(f\"Missing one of the required columns: {required_columns - set(df.columns)}\")\n",
    "\n",
    "# Enable progress bar for apply\n",
    "tqdm.pandas()\n",
    "\n",
    "# Create temporary working DataFrame\n",
    "df_temp = df.copy()\n",
    "df_temp['question_type'] = df_temp['translated_question'].progress_apply(classify_urdu_question)\n",
    "\n",
    "# --- Evaluation Logic ---\n",
    "def is_correct(row):\n",
    "    level = str(row['level']).strip().lower()\n",
    "    q_type = str(row['question_type']).strip().lower()\n",
    "\n",
    "    if level == 'easy' and q_type == 'singlehop':\n",
    "        return True\n",
    "    elif level in {'medium', 'hard'} and q_type == 'multihop':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "df_temp['correct_classification'] = df_temp.apply(is_correct, axis=1)\n",
    "\n",
    "# --- Evaluation Summary ---\n",
    "total = len(df_temp)\n",
    "correct = df_temp['correct_classification'].sum()\n",
    "accuracy = correct / total * 100\n",
    "\n",
    "print(f\"\\n✅ Total questions: {total}\")\n",
    "print(f\"✅ Correctly classified: {correct}\")\n",
    "print(f\"✅ Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# --- Per-level Accuracy ---\n",
    "print(\"\\n🔍 Accuracy by level:\")\n",
    "for level in df_temp['level'].unique():\n",
    "    subset = df_temp[df_temp['level'].str.lower() == level.lower()]\n",
    "    correct_subset = subset['correct_classification'].sum()\n",
    "    total_subset = len(subset)\n",
    "    acc = correct_subset / total_subset * 100 if total_subset else 0\n",
    "    print(f\"  {level}: {acc:.2f}% ({correct_subset}/{total_subset})\")\n",
    "\n",
    "# --- Optional: Display misclassified examples ---\n",
    "print(\"\\n❌ Misclassified questions:\")\n",
    "print(df_temp[df_temp['correct_classification'] == False][['translated_question', 'level', 'question_type']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d974d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  translated_question   level question_type\n",
      "0   سیری بی 2017 - 2017 (اسپانسرشپ کی وجوہات کی بن...    easy      multihop\n",
      "1   \"آکسفورڈ کالج کے ایک ساتھی ایلک نیلر ڈکن نے کہ...    easy      multihop\n",
      "3   کون سا کردار ، ڈین کاسٹیلینیٹا کی آواز ، سمپسن...    easy      multihop\n",
      "4      کون تھا ایک حصہ S#arp، لی Ji-hye یا کرٹس رائٹ؟    easy      multihop\n",
      "5   امریکی باسکٹ بال ٹیم نے اس سال کے آخر میں شکاگ...    easy      multihop\n",
      "6   لیٹروب بریوری کمپنی ، جو 1839 میں قائم ہوئی تھ...    easy      multihop\n",
      "7   امریکی فوج کے ایک افسر اور منشیات کے اسمگلنگ ک...    easy      multihop\n",
      "8   اینڈریو مارٹن ڈوبر ، ایک امریکی مخلوط مارشل آر...    easy      multihop\n",
      "9   ایمینم کے البم مارشل میتھرز ایل پی 2 پر کون سا...    easy      multihop\n",
      "12  ایمی لی اور ٹی ایس ایم ، موسیقی کی کس صنف سے م...    easy      multihop\n",
      "13  ریاستہائے متحدہ امریکہ کے ہوائی اڈے پر ، یونائ...    easy      multihop\n",
      "14  نیکول مچل ایک امریکی موسمیاتی ماہر ہیں جو پہلی...    easy      multihop\n",
      "15  \"پسیوڈوٹسوگا ، جو شمالی امریکہ اور مشرقی ایشیا...    easy      multihop\n",
      "16  جوآن سیبسٹین کیبل اور جان لائیڈ کون سا کھیل کھ...    easy      multihop\n",
      "17  کیم لیپ کون سا جنوبی کوریائی گرل گروپ کا ایک ا...    easy      multihop\n",
      "18  بلیک اسٹون چیری اور جین لیوز ایزبل دونوں برطان...  medium     singlehop\n",
      "19  نیوزی لینڈ کی بادشاہت کی ایک ایسی رہنما ہے جس ...  medium     singlehop\n",
      "32  \"اس ویب سائٹ کا نام \"\"پینیلوپ پرنسس آف پیٹس\"\" ...  medium     singlehop\n",
      "40  \"آئرلینڈ کے قانون سازوں نے \"\"آئرلینڈ کونسل\"\" ک...  medium     singlehop\n",
      "44  لیک ڈسٹرکٹ نیشنل پارک میں مخصوص گرنے کی اونچائ...  medium     singlehop\n",
      "47  فرانسیسی فٹ بالر اور فٹ بال کوچ مائیکل سیوینسن...  medium     singlehop\n",
      "50  کونسی کالج ٹیم بھائیوں کولٹ اور کیس McCoy کے ل...    hard     singlehop\n",
      "55           Pandian اور الپائن Mastiff کے درمیان فرق    hard     singlehop\n",
      "57         کون بڑا ہے، رابرٹ Lindstedt یا پیٹ Norval؟    hard     singlehop\n",
      "58  ڈینیل میسی نے 'دی کوئینز گارڈز' میں کون سے ادا...    hard     singlehop\n",
      "61  بھارت کی ایک ایسی ریاست جس کا دارالحکومت بھانڈ...    hard     singlehop\n",
      "63  لیک ووڈ رنچ ایک ماسٹر پلانڈ کمیونٹی ہے جس میں ...    hard     singlehop\n",
      "73    فلم سیکس ڈرائیو میں امانڈا کرو کا کردار کیا ہے؟    hard     singlehop\n",
      "74  اس نے 1889 میں برمنگھم ، انگلینڈ میں 2010 اے ا...    hard     singlehop\n",
      "75  مشی گن کے سابق گورنر ہاورڈ ایڈلسن نے اپنے انتخ...    hard     singlehop\n",
      "81  کون سی فلم کا پریمیئر پہلے ہوا، پوکیمون: آرسیئ...    hard     singlehop\n",
      "84            مسجد الحسن کا قیام کس خلیفہ نے کیا تھا؟    hard     singlehop\n",
      "97   کون سا کھلاڑی 36 ویں ٹولون ٹورنامنٹ جیت سکتا ہے؟    hard     singlehop\n"
     ]
    }
   ],
   "source": [
    "print(df_temp[df_temp['correct_classification'] == False][['translated_question', 'level', 'question_type']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1646b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2      True\n",
       "3      True\n",
       "4     False\n",
       "      ...  \n",
       "93    False\n",
       "94    False\n",
       "95    False\n",
       "96     True\n",
       "97    False\n",
       "Name: correct_classification, Length: 98, dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp['correct_classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d8dc8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             _multihop\n",
       "1     Question: What is the best title for this sent...\n",
       "2                                             singlehop\n",
       "3                                             singlehop\n",
       "4                                not enough information\n",
       "                            ...                        \n",
       "93                                               simple\n",
       "94                                               simple\n",
       "95                                            singlehop\n",
       "96                                             multihop\n",
       "97                                            singlehop\n",
       "Name: question_type, Length: 98, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp['question_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76a145db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\hammad workings\\Thesis\\Multihop for Urdu\\Multihop for Urdu\\code\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\23030013\\.cache\\huggingface\\hub\\models--bigscience--bloomz-3b. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"bigscience/bloomz-3b\"  # or bloom-1b7/bloom-3b\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afdd8fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Break the following Urdu question into 2 logical sub-questions needed to answer it:\n",
      "Question: اگر لاہور میں فضائی آلودگی کی سطح زیادہ ہے اور فضائی آلودگی نمونیا کا سبب بن سکتی ہے، تو لاہور میں رہنے والوں کو نمونیا سے بچنے کے لیے کیا اقدامات کرنے چاہئیں؟\n",
      "* لاہور میں فضائی آلودگی کی سطح زیادہ ہے\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"\n",
    "Break the following Urdu question into 2 logical sub-questions needed to answer it:\n",
    "Question: اگر لاہور میں فضائی آلودگی کی سطح زیادہ ہے اور فضائی آلودگی نمونیا کا سبب بن سکتی ہے، تو لاہور میں رہنے والوں کو نمونیا سے بچنے کے لیے کیا اقدامات کرنے چاہئیں؟\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_length=300)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1616b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "ollama.pull('mistral:latest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e7effd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def decompose_urdu_query(urdu_query: str) -> dict:\n",
    "    \"\"\"Returns dictionary with q1 and q2 keys containing sub-questions\"\"\"\n",
    "    refined_prompt = f\"\"\"\n",
    "**Role**: You are an expert Urdu linguistic analyst specializing in question decomposition. Your task is to break down complex Urdu questions into their fundamental components.\n",
    "\n",
    "**Task Instructions**:\n",
    "1. Carefully analyze the given Urdu question to identify its core components\n",
    "2. Extract exactly 2 sub-questions that:\n",
    "   - Are necessary to answer the main question\n",
    "   - Cover distinct aspects of the problem\n",
    "   - Have clear logical progression (answer to q1 helps answer q2)\n",
    "3. Both sub-questions must:\n",
    "   - Be in proper Urdu language\n",
    "   - Be grammatically correct\n",
    "   - Be clear and concise\n",
    "   - Use relevant domain terminology\n",
    "\n",
    "**Output Format Requirements**:\n",
    "- Use EXACTLY this format:\n",
    "  q1: [پہلا ذیلی سوال]\n",
    "  q2: [دوسرا ذیلی سوال]\n",
    "- Each sub-question must be on a new line\n",
    "- Do not include any additional commentary or explanation\n",
    "- Do not number the questions (use only q1:/q2: prefixes)\n",
    "\n",
    "**Example 1**:\n",
    "Input: اگر لاہور میں فضائی آلودگی کی سطح دہلی سے زیادہ ہے اور فضائی آلودگی پھیپھڑوں کے کینسر کا سبب بن سکتی ہے، تو لاہور کے رہائشیوں کو کس قسم کے طبی چیک اپ کروانے چاہئیں؟\n",
    "Output:\n",
    "q1: لاہور اور دہلی میں فضائی آلودگی کی سطح کا موازنہ کیا ہے؟\n",
    "q2: فضائی آلودگی پھیپھڑوں کے کینسر کا سبب کیسے بنتی ہے؟\n",
    "\n",
    "**Example 2**:\n",
    "Input: اگر کراچی میں بجلی کے نرخ 30% بڑھ گئے ہیں اور یہ صنعتوں کو متاثر کر رہا ہے، تو حکومت کو کون سی سبسڈیاں دینی چاہئیں؟\n",
    "Output:\n",
    "q1: کراچی میں بجلی کے نرخوں میں اضافے کی موجودہ شرح کیا ہے؟\n",
    "q2: بجلی کے مہنگے ہونے سے صنعتوں پر کس قسم کے اثرات مرتب ہو رہے ہیں؟\n",
    "\n",
    "**Current Task**:\n",
    "Input: {urdu_query}\n",
    "Output:\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = ollama.generate(\n",
    "            model='mistral',\n",
    "            prompt=refined_prompt,\n",
    "            options={\n",
    "                'temperature': 0.5,\n",
    "                'num_ctx': 2048\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        output = response['response'].strip()\n",
    "        \n",
    "        result = {}\n",
    "        for line in output.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if line.startswith('q1:'):\n",
    "                result['q1'] = line[3:].strip()\n",
    "            elif line.startswith('q2:'):\n",
    "                result['q2'] = line[3:].strip()\n",
    "        \n",
    "        return result if len(result) == 2 else {}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Decomposition error: {str(e)}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fbc45220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1: اسلام آباد میں ٹریفک جام کی شکایات میں اضافے کی موجودہ شرح کیا ہے؟\n",
      "q2: نقل و حمل پالیسیوں کے وجہ سے ٹریفک جام کی شکایت کی بڑھنے سے کس قسم کے اثرات مرتب ہو رہے ہیں؟\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Correct usage:\n",
    "your_query = \"اگر اسلام آباد میں ٹریفک جام کی شکایات 50% بڑھ گئی ہیں اور یہ شہر کی نقل و حمل کی ناکافی پالیسیوں کی وجہ سے ہے، تو حکومت کو کون سے نئے ٹریفک قوانین متعارف کروانے چاہئیں؟\"\n",
    "\n",
    "result = decompose_urdu_query(your_query)\n",
    "if result:\n",
    "    print(f\"q1: {result.get('q1', 'Not generated')}\")\n",
    "    print(f\"q2: {result.get('q2', 'Not generated')}\")\n",
    "else:\n",
    "    print(\"Failed to decompose the query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a57f638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Environmental Policy\n",
    "your_query_1 = \"اگر دریائے سندھ میں آلودگی کی شرح 40% بڑھ گئی ہے اور یہ زراعت کو متاثر کر رہی ہے، تو پنجاب حکومت کو کون سے فوری اقدامات کرنے چاہئیں؟\"\n",
    "\n",
    "# 2. Public Health\n",
    "your_query_2 = \"اگر کراچی میں ڈینگی کے کیسز میں 150% اضافہ ہوا ہے اور بارشوں کا غیر معمولی نمونہ اس کی بنیادی وجہ ہے، تو شہری انتظامیہ کو کون سی احتیاطی تدابیر اختیار کرنی چاہئیں؟\"\n",
    "\n",
    "# 3. Education Reform\n",
    "your_query_3 = \"اگر پنجاب کے سرکاری اسکولوں میں پڑھائی کا معیار 60% طلبہ کے لیے ناکافی ہے اور اساتذہ کی تربیت میں کمی اس کی وجہ ہے، تو تعلیمی بجٹ میں کس شعبے کو ترجیح دی جانی چاہیے؟\"\n",
    "\n",
    "# 4. Economic Development\n",
    "your_query_4 = \"اگر پاکستان میں برآمدات 25% کم ہو گئی ہیں اور بین الاقوامی معیارات پر پورا نہ اترنا اس کی بنیادی وجہ ہے، تو وزارت تجارت کو کون سی نئی پالیسیاں بنانی چاہئیں؟\"\n",
    "\n",
    "# 5. Urban Planning\n",
    "your_query_5 = \"اگر اسلام آباد میں ٹریفک حادثات میں 30% اضافہ ہوا ہے اور سڑکوں کی ناقص ڈیزائننگ اس کی وجہ ہے، تو سی ڈی اے کو کون سے تعمیراتی معیارات تبدیل کرنے چاہئیں؟\"\n",
    "\n",
    "# 6. Agricultural Crisis\n",
    "your_query_6 = \"اگر گندم کی پیداوار میں 20% کمی واقع ہوئی ہے اور کسانوں کو جدید ادویات تک رسائی نہ ہونا اس کی وجہ ہے، تو زرعی تحقیقاتی ادارے کو کون سی سہولیات فراہم کرنی چاہئیں؟\"\n",
    "\n",
    "# 7. Energy Sector\n",
    "your_query_7 = \"اگر لوڈ شیڈنگ میں 45% اضافہ ہوا ہے اور پرانے جنریٹرز کا ناکارہ ہونا اس کی بنیادی وجہ ہے، تو وزارت توانائی کو کون سے نئے منصوبے شروع کرنے چاہئیں؟\"\n",
    "\n",
    "# 8. Healthcare Access\n",
    "your_query_8 = \"اگر دیہی علاقوں میں 70% آبادی کو بنیادی صحت کی سہولیات میسر نہیں اور ڈاکٹروں کی کمی اس کی وجہ ہے، تو صوبائی حکومت کو کون سی تربیتی اسکیمیں شروع کرنی چاہئیں؟\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "21666cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Query 1:\n",
      "اگر دریائے سندھ میں آلودگی کی شرح 40% بڑھ گئی ہے اور یہ زراعت کو متاثر کر رہی ہے، تو پنجاب حکومت کو کون سے فوری اقدامات کرنے چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: دریائے سندھ میں آلودگی کی شرح 40% کی موجودہ شرح کیا گیا ہے؟\n",
      "q2: زراعت کو دریائے سندھ میں آلودگی کے اثرات متاثر کرنے سے کس قسم کے اثرات مرتب ہو رہی ہیں؟\n",
      "\n",
      "Testing Query 2:\n",
      "اگر کراچی میں ڈینگی کے کیسز میں 150% اضافہ ہوا ہے اور بارشوں کا غیر معمولی نمونہ اس کی بنیادی وجہ ہے، تو شہری انتظامیہ کو کون سی احتیاطی تدابیر اختیار کرنی چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: کراچی میں ڈینگی کے کیسز میں 150% اضافہ کیا گیا ہے؟\n",
      "q2: بارشوں کا غیر معمولی نمونہ اس کی بنیادی وجہ سے کیسے حالت پھاڑتی ہے شہری انتظامیہ؟\n",
      "\n",
      "Testing Query 3:\n",
      "اگر پنجاب کے سرکاری اسکولوں میں پڑھائی کا معیار 60% طلبہ کے لیے ناکافی ہے اور اساتذہ کی تربیت میں کمی اس کی وجہ ہے، تو تعلیمی بجٹ میں کس شعبے کو ترجیح دی جانی چاہیے؟\n",
      "\n",
      "Decomposition:\n",
      "q1: پنجاب کے سرکاری اسکولوں میں پڑھائی کا معیار 60% طلبہ کے لئے کیا ہے؟\n",
      "q2: استعدادزدہ کی تربیت میں کمی کو کس شعبے کے وجہ سے ہے؟\n",
      "\n",
      "Testing Query 4:\n",
      "اگر پاکستان میں برآمدات 25% کم ہو گئی ہیں اور بین الاقوامی معیارات پر پورا نہ اترنا اس کی بنیادی وجہ ہے، تو وزارت تجارت کو کون سی نئی پالیسیاں بنانی چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: پاکستان میں برآمدات کی محصولات کی معاملات پر 25% کم ہوئی ہے یا نہیں؟\n",
      "q2: بین الاقوامی معیارات پر پاکستان کی برآمدات میں کس قسم کے اثرات ہیں؟\n",
      "\n",
      "Testing Query 5:\n",
      "اگر اسلام آباد میں ٹریفک حادثات میں 30% اضافہ ہوا ہے اور سڑکوں کی ناقص ڈیزائننگ اس کی وجہ ہے، تو سی ڈی اے کو کون سے تعمیراتی معیارات تبدیل کرنے چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: اسلام آباد میں ٹریفک حادثات میں 30% اضافہ شہور کے پانچھے قسم کے طبقے کیا گئے ہیں؟\n",
      "q2: ٹریفک حادثات میں 30% اضافہ کے علاوہ، سڑکوں کی ناقص ڈیزائننگ کی وجہ سے تبدیل کرنے کے لیے کچھ کام کی جانے کے قسم کے اثر مرتب ہیں؟\n",
      "\n",
      "Testing Query 6:\n",
      "اگر گندم کی پیداوار میں 20% کمی واقع ہوئی ہے اور کسانوں کو جدید ادویات تک رسائی نہ ہونا اس کی وجہ ہے، تو زرعی تحقیقاتی ادارے کو کون سی سہولیات فراہم کرنی چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: گندم پیداوار میں 20% کمی واقع ہوئی ہے کیا معلوم ہے؟\n",
      "q2: جدید ادویات تک رسائی نہ ہونے کی وجہ سے زرعی تحقیقاتی ادارے پر کس قسم کے اثرات مرتب ہوئی ہیں؟\n",
      "\n",
      "Testing Query 7:\n",
      "اگر لوڈ شیڈنگ میں 45% اضافہ ہوا ہے اور پرانے جنریٹرز کا ناکارہ ہونا اس کی بنیادی وجہ ہے، تو وزارت توانائی کو کون سے نئے منصوبے شروع کرنے چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: لوڈ شیڈنگ میں 45% اضافہ کی موجودہ شرح کیا ہے؟\n",
      "q2: پرانے جنریٹرز کا ناکارہ ہونے سے تعلق رکھنے والے نئے منصوبے کی بنیادی وجہ کیسے ہوتی ہیں؟\n",
      "\n",
      "Testing Query 8:\n",
      "اگر دیہی علاقوں میں 70% آبادی کو بنیادی صحت کی سہولیات میسر نہیں اور ڈاکٹروں کی کمی اس کی وجہ ہے، تو صوبائی حکومت کو کون سی تربیتی اسکیمیں شروع کرنی چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: دیہی علاقوں میں 70% آبادی کو بنیادی صحت کی سہولیات میسر ہیں یا نہیں؟\n",
      "q2: ڈاکٹروں کی کمی کو آبادی علاقوں میں کس قسم کے وجہ دیتی ہے؟\n"
     ]
    }
   ],
   "source": [
    "queries = [your_query_1, your_query_2, your_query_3, your_query_4, your_query_5, your_query_6, your_query_7, your_query_8]\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"\\nTesting Query {i}:\")\n",
    "    print(query)\n",
    "    result = decompose_urdu_query(query)\n",
    "    print(\"\\nDecomposition:\")\n",
    "    print(f\"q1: {result.get('q1', 'N/A')}\")\n",
    "    print(f\"q2: {result.get('q2', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6faa4824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "ollama.pull('llama3:8b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2eb6bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def decompose_urdu_query(urdu_query: str) -> dict:\n",
    "    \"\"\"Returns dictionary with q1 and q2 keys containing sub-questions\"\"\"\n",
    "    refined_prompt = f\"\"\"\n",
    "**Role**: You are an expert Urdu linguistic analyst specializing in question decomposition. Your task is to break down complex Urdu questions into their fundamental components.\n",
    "\n",
    "**Task Instructions**:\n",
    "1. Carefully analyze the given Urdu question to identify its core components\n",
    "2. Extract exactly 2 sub-questions that:\n",
    "   - Are necessary to answer the main question\n",
    "   - Cover distinct aspects of the problem\n",
    "   - Have clear logical progression (answer to q1 helps answer q2)\n",
    "3. Both sub-questions must:\n",
    "   - Be in proper Urdu language\n",
    "   - Be grammatically correct\n",
    "   - Be clear and concise\n",
    "   - Use relevant domain terminology\n",
    "\n",
    "**Output Format Requirements**:\n",
    "- Use EXACTLY this format:\n",
    "  q1: [پہلا ذیلی سوال]\n",
    "  q2: [دوسرا ذیلی سوال]\n",
    "- Each sub-question must be on a new line\n",
    "- Do not include any additional commentary or explanation\n",
    "- Do not number the questions (use only q1:/q2: prefixes)\n",
    "\n",
    "**Example 1**:\n",
    "Input: اگر لاہور میں فضائی آلودگی کی سطح دہلی سے زیادہ ہے اور فضائی آلودگی پھیپھڑوں کے کینسر کا سبب بن سکتی ہے، تو لاہور کے رہائشیوں کو کس قسم کے طبی چیک اپ کروانے چاہئیں؟\n",
    "Output:\n",
    "q1: لاہور اور دہلی میں فضائی آلودگی کی سطح کا موازنہ کیا ہے؟\n",
    "q2: فضائی آلودگی پھیپھڑوں کے کینسر کا سبب کیسے بنتی ہے؟\n",
    "\n",
    "**Example 2**:\n",
    "Input: اگر کراچی میں بجلی کے نرخ 30% بڑھ گئے ہیں اور یہ صنعتوں کو متاثر کر رہا ہے، تو حکومت کو کون سی سبسڈیاں دینی چاہئیں؟\n",
    "Output:\n",
    "q1: کراچی میں بجلی کے نرخوں میں اضافے کی موجودہ شرح کیا ہے؟\n",
    "q2: بجلی کے مہنگے ہونے سے صنعتوں پر کس قسم کے اثرات مرتب ہو رہے ہیں؟\n",
    "\n",
    "**Current Task**:\n",
    "Input: {urdu_query}\n",
    "Output:\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = ollama.generate(\n",
    "            model='llama3:8b',\n",
    "            prompt=refined_prompt,\n",
    "            options={\n",
    "                'temperature': 0.5,\n",
    "                'num_ctx': 2048\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        output = response['response'].strip()\n",
    "        \n",
    "        result = {}\n",
    "        for line in output.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if line.startswith('q1:'):\n",
    "                result['q1'] = line[3:].strip()\n",
    "            elif line.startswith('q2:'):\n",
    "                result['q2'] = line[3:].strip()\n",
    "        \n",
    "        return result if len(result) == 2 else {}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Decomposition error: {str(e)}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6d938ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Query 1:\n",
      "اگر دریائے سندھ میں آلودگی کی شرح 40% بڑھ گئی ہے اور یہ زراعت کو متاثر کر رہی ہے، تو پنجاب حکومت کو کون سے فوری اقدامات کرنے چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: دریائے سندھ میں آلودگی کی شرح میں اضافے کی موجودہ شرح کیا ہے؟\n",
      "q2: آلودگی سے زراعت کو متاثر کر رہی ہے، تو پنجاب حکومت کو کس قسم کے فلاحی اقدامات لینے چاہئیں؟\n",
      "\n",
      "Testing Query 2:\n",
      "اگر کراچی میں ڈینگی کے کیسز میں 150% اضافہ ہوا ہے اور بارشوں کا غیر معمولی نمونہ اس کی بنیادی وجہ ہے، تو شہری انتظامیہ کو کون سی احتیاطی تدابیر اختیار کرنی چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: کراچی میں ڈینگی کے کیسز میں اضافے کی شرح کیا ہے؟\n",
      "q2: بارشوں کا غیر معمولی نمونہ ڈینگی کے اضافے کی بنیادی وجہ کیسے بنتی ہے؟\n",
      "\n",
      "Testing Query 3:\n",
      "اگر پنجاب کے سرکاری اسکولوں میں پڑھائی کا معیار 60% طلبہ کے لیے ناکافی ہے اور اساتذہ کی تربیت میں کمی اس کی وجہ ہے، تو تعلیمی بجٹ میں کس شعبے کو ترجیح دی جانی چاہیے؟\n",
      "\n",
      "Decomposition:\n",
      "q1: پنجاب کے سرکاری اسکولوں میں پڑھائی کا معیار کیا ہے؟\n",
      "q2: تعلیمی بجٹ میں تربیت کی کمی کس قسم کے اثرات مرتب ہو رہے ہیں؟\n",
      "\n",
      "Testing Query 4:\n",
      "اگر پاکستان میں برآمدات 25% کم ہو گئی ہیں اور بین الاقوامی معیارات پر پورا نہ اترنا اس کی بنیادی وجہ ہے، تو وزارت تجارت کو کون سی نئی پالیسیاں بنانی چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: پاکستان میں برآمدات میں اضافے کی موجودہ شرح کیا ہے؟\n",
      "q2: بین الاقوامی معیارات پر پورا نہ اترنا سے پاکستان کی برآمدات میں کمی کی بنیادی وجہ کیسے ہے؟\n",
      "\n",
      "Testing Query 5:\n",
      "اگر اسلام آباد میں ٹریفک حادثات میں 30% اضافہ ہوا ہے اور سڑکوں کی ناقص ڈیزائننگ اس کی وجہ ہے، تو سی ڈی اے کو کون سے تعمیراتی معیارات تبدیل کرنے چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: اسلام آباد میں ٹریفک حادثات میں اضافے کی موجودہ شرح کیا ہے؟\n",
      "q2: سڑکوں کی ناقص ڈیزائننگ ٹریفک حادثات میں اضافے کی وجہ کیسے بنتی ہے؟\n",
      "\n",
      "Testing Query 6:\n",
      "اگر گندم کی پیداوار میں 20% کمی واقع ہوئی ہے اور کسانوں کو جدید ادویات تک رسائی نہ ہونا اس کی وجہ ہے، تو زرعی تحقیقاتی ادارے کو کون سی سہولیات فراہم کرنی چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: گندم کی پیداوار میں 20% کمی واقع ہوئی ہے، تو اس کی وجہ کیا ہے؟\n",
      "q2: کسانوں کو جدید ادویات تک رسائی نہ ہونا گندم کی پیداوار میں کمی کی وجہ کیسے بنتی ہے؟\n",
      "\n",
      "Testing Query 7:\n",
      "اگر لوڈ شیڈنگ میں 45% اضافہ ہوا ہے اور پرانے جنریٹرز کا ناکارہ ہونا اس کی بنیادی وجہ ہے، تو وزارت توانائی کو کون سے نئے منصوبے شروع کرنے چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: لوڈ شیڈنگ میں اضافے کی موجودہ شرح کیا ہے؟\n",
      "q2: پرانے جنریٹرز کا ناکارہ ہونا لوڈ شیڈنگ میں اضافے کی بنیادی وجہ کیسے ہے؟\n",
      "\n",
      "Testing Query 8:\n",
      "اگر دیہی علاقوں میں 70% آبادی کو بنیادی صحت کی سہولیات میسر نہیں اور ڈاکٹروں کی کمی اس کی وجہ ہے، تو صوبائی حکومت کو کون سی تربیتی اسکیمیں شروع کرنی چاہئیں؟\n",
      "\n",
      "Decomposition:\n",
      "q1: دیہی علاقوں میں آبادی کا 70% بنیادی صحت کی سہولیات سے محروم ہے؟\n",
      "q2: ڈاکٹروں کی کمی دیہی علاقوں میں صحت کی سہولیات فراہم کرنے میں کس قسم کے Challenges کو پیش کردیتی ہے؟\n"
     ]
    }
   ],
   "source": [
    "queries = [your_query_1, your_query_2, your_query_3, your_query_4, your_query_5, your_query_6, your_query_7, your_query_8]\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"\\nTesting Query {i}:\")\n",
    "    print(query)\n",
    "    result = decompose_urdu_query(query)\n",
    "    print(\"\\nDecomposition:\")\n",
    "    print(f\"q1: {result.get('q1', 'N/A')}\")\n",
    "    print(f\"q2: {result.get('q2', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "896eb0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def query_context_relevance_check(query_urdu: str, context_urdu: str) -> bool:\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in understanding the meaning and relevance of questions and their supporting information.\n",
    "\n",
    "Your task is to check whether a given *context* is relevant to a given *question*. Both the question and the context are written in Urdu.\n",
    "\n",
    "- If the context provides information that could help answer or understand the question, reply: True\n",
    "- If the context is not helpful or unrelated to the question, reply: False\n",
    "\n",
    "---\n",
    "\n",
    "Here is the input:\n",
    "\n",
    "Question (Urdu): {query_urdu}\n",
    "\n",
    "Context (Urdu): {context_urdu}\n",
    "\n",
    "Is the context relevant to the question?\n",
    "Answer (True/False):\"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3:8b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    answer = response['message']['content'].strip().lower()\n",
    "    return 'true' in answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a49c9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_test_cases = [\n",
    "    {\n",
    "        \"query\": \"پاکستان کا قومی پھول کون سا ہے؟\",\n",
    "        \"context\": \"کراچی پاکستان کا سب سے بڑا شہر ہے۔\",\n",
    "        \"expected\": False\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"اردو زبان کی ابتدا کہاں ہوئی؟\",\n",
    "        \"context\": \"پاکستانی کرکٹ ٹیم نے ورلڈ کپ 1992 میں جیتا۔\",\n",
    "        \"expected\": False\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"قائداعظم کی تاریخ پیدائش کیا ہے؟\",\n",
    "        \"context\": \"پاکستان کا پرچم دو رنگوں پر مشتمل ہے: سبز اور سفید۔\",\n",
    "        \"expected\": False\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"خلا میں سب سے پہلے جانے والا انسان کون تھا؟\",\n",
    "        \"context\": \"پاکستان میں سب سے بلند پہاڑ کے ٹو ہے۔\",\n",
    "        \"expected\": False\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"پاکستان کے پہلے صدر کون تھے؟\",\n",
    "        \"context\": \"پاکستان میں زیادہ تر لوگ اردو اور پنجابی بولتے ہیں۔\",\n",
    "        \"expected\": False\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"علامہ اقبال کی تعلیم کہاں سے ہوئی؟\",\n",
    "        \"context\": \"کراچی میں سب سے مشہور ساحل کلفٹن ہے۔\",\n",
    "        \"expected\": False\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"برصغیر کی تقسیم کب ہوئی؟\",\n",
    "        \"context\": \"دریائے سندھ پاکستان کا سب سے بڑا دریا ہے۔\",\n",
    "        \"expected\": False\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"لاہور کس دریا کے کنارے واقع ہے؟\",\n",
    "        \"context\": \"اسلام آباد کو 1960 میں دارالحکومت بنایا گیا تھا۔\",\n",
    "        \"expected\": False\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"پاکستان کی سب سے بڑی یونیورسٹی کون سی ہے؟\",\n",
    "        \"context\": \"پاکستان میں چاروں موسم ہوتے ہیں: گرمی، سردی، خزاں، اور بہار۔\",\n",
    "        \"expected\": False\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"بابائے قوم کا خطاب کسے دیا گیا؟\",\n",
    "        \"context\": \"پاکستان کی سب سے لمبی شاہراہ قراقرم ہائی وے ہے۔\",\n",
    "        \"expected\": False\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d6bfb807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Expected: False, Got: False, ✅\n",
      "Test 2: Expected: False, Got: False, ✅\n",
      "Test 3: Expected: False, Got: False, ✅\n",
      "Test 4: Expected: False, Got: False, ✅\n",
      "Test 5: Expected: False, Got: False, ✅\n",
      "Test 6: Expected: False, Got: False, ✅\n",
      "Test 7: Expected: False, Got: False, ✅\n",
      "Test 8: Expected: False, Got: False, ✅\n",
      "Test 9: Expected: False, Got: False, ✅\n",
      "Test 10: Expected: False, Got: False, ✅\n"
     ]
    }
   ],
   "source": [
    "for i, case in enumerate(false_test_cases, start=1):\n",
    "    result = query_context_relevance_check(case[\"query\"], case[\"context\"])\n",
    "    print(f\"Test {i}: Expected: {case['expected']}, Got: {result}, {'✅' if result == case['expected'] else '❌'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed992f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
